{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Besutodesuka/GenAI/blob/main/2_PyTorch_Tutorials.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PyTorch Tutorials\n",
        "## Checking CUDA device"
      ],
      "metadata": {
        "id": "-BpuGC-8gO02"
      },
      "id": "-BpuGC-8gO02"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59b57dda-9650-4296-8b8b-d54b184b684b",
      "metadata": {
        "id": "59b57dda-9650-4296-8b8b-d54b184b684b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a6f385c-d0d6-4670-afa1-dc03d4d5439d",
      "metadata": {
        "id": "0a6f385c-d0d6-4670-afa1-dc03d4d5439d"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensors"
      ],
      "metadata": {
        "id": "77TPkckVgiXJ"
      },
      "id": "77TPkckVgiXJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9e8d1be-149b-4b50-8a16-71b36e123e6d",
      "metadata": {
        "id": "f9e8d1be-149b-4b50-8a16-71b36e123e6d"
      },
      "outputs": [],
      "source": [
        "# Scalars / vectors / matrices\n",
        "a = torch.tensor(3.14)\n",
        "b = torch.tensor([1.0, 2.0, 3.0])\n",
        "c = torch.tensor([[1, 2], [3, 4]])\n",
        "\n",
        "print(\"a:\", a, \"shape:\", a.shape, \"dtype:\", a.dtype)\n",
        "print(\"b:\", b, \"shape:\", b.shape, \"dtype:\", b.dtype)\n",
        "print(\"c:\\n\", c, \"shape:\", c.shape, \"dtype:\", c.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86b26e53-53c9-4f66-b4c0-aeb26fcd538a",
      "metadata": {
        "id": "86b26e53-53c9-4f66-b4c0-aeb26fcd538a"
      },
      "outputs": [],
      "source": [
        "x_np = np.array([1, 2, 3], dtype=np.float32)\n",
        "x_t = torch.from_numpy(x_np)\n",
        "\n",
        "print(\"NumPy:\", x_np, type(x_np))\n",
        "print(\"Torch:\", x_t, type(x_t))\n",
        "\n",
        "# Convert torch -> numpy\n",
        "x_back = x_t.numpy()\n",
        "print(\"Back to NumPy:\", x_back, type(x_back))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4e051bb-3108-4a5e-a6aa-454dfc3b907c",
      "metadata": {
        "id": "d4e051bb-3108-4a5e-a6aa-454dfc3b907c"
      },
      "outputs": [],
      "source": [
        "x_t.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0891ad5d-0a43-4cb1-a890-373ae63d36ca",
      "metadata": {
        "id": "0891ad5d-0a43-4cb1-a890-373ae63d36ca"
      },
      "outputs": [],
      "source": [
        "x = torch.randn(3, 4, 5, device='cuda:0')\n",
        "x.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "787ab74c-1c91-4ef7-9167-b7f4b0631a20",
      "metadata": {
        "id": "787ab74c-1c91-4ef7-9167-b7f4b0631a20"
      },
      "outputs": [],
      "source": [
        "x_t1 = x_t.to(device='cuda')\n",
        "x_t1.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3d66ec9-c0ee-49ed-bed1-e3822556a0db",
      "metadata": {
        "id": "c3d66ec9-c0ee-49ed-bed1-e3822556a0db"
      },
      "outputs": [],
      "source": [
        "z = torch.zeros(2, 3)\n",
        "o = torch.ones(2, 3)\n",
        "r = torch.rand(2, 3)\n",
        "t = torch.tensor([10, 20, 30])\n",
        "a = torch.arange(0, 10)\n",
        "\n",
        "print(\"zeros:\\n\", z)\n",
        "print(\"ones:\\n\", o)\n",
        "print(\"rand:\\n\", r)\n",
        "print(\"tensor:\", t)\n",
        "print(\"arange:\", a)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3124fddd-140e-45b5-b058-99ee0b63c003",
      "metadata": {
        "id": "3124fddd-140e-45b5-b058-99ee0b63c003"
      },
      "outputs": [],
      "source": [
        "z.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "986aadb0-b16e-40cc-9c85-a241375af9c3",
      "metadata": {
        "id": "986aadb0-b16e-40cc-9c85-a241375af9c3"
      },
      "outputs": [],
      "source": [
        "z.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb43d07f-6fa0-4e7b-b95e-35a3cbe7b370",
      "metadata": {
        "id": "eb43d07f-6fa0-4e7b-b95e-35a3cbe7b370"
      },
      "outputs": [],
      "source": [
        "z.device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch Operations"
      ],
      "metadata": {
        "id": "RiBuJpjFguJE"
      },
      "id": "RiBuJpjFguJE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dcfa3f5-111d-4106-a823-f10cd8a38295",
      "metadata": {
        "id": "2dcfa3f5-111d-4106-a823-f10cd8a38295"
      },
      "outputs": [],
      "source": [
        "B, C, H, W = 32, 3, 64, 64\n",
        "images = torch.rand(B, C, H, W)\n",
        "\n",
        "print(\"images shape:\", images.shape)  # (32, 3, 64, 64)\n",
        "\n",
        "# Example: flatten per-image into vectors for an MLP\n",
        "flat = images.view(B, -1)\n",
        "print(\"flattened shape:\", flat.shape)  # (32, 12288)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee1c1ada-bc9e-4ebb-b84e-875aa37ebf12",
      "metadata": {
        "id": "ee1c1ada-bc9e-4ebb-b84e-875aa37ebf12"
      },
      "outputs": [],
      "source": [
        "images[1].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edaf3e1d-af77-45cd-979b-266000329070",
      "metadata": {
        "id": "edaf3e1d-af77-45cd-979b-266000329070"
      },
      "outputs": [],
      "source": [
        "A = torch.ones(2, 3)\n",
        "b = torch.tensor([10.0, 20.0, 30.0])  # shape (3,)\n",
        "\n",
        "print(\"A shape:\", A.shape)\n",
        "print(\"b shape:\", b.shape)\n",
        "\n",
        "# Broadcasting: b is expanded to (2,3)\n",
        "C = A + b\n",
        "print(\"A + b:\\n\", C)\n",
        "\n",
        "# Danger example: (2,3) + (2,1) broadcasts differently\n",
        "d = torch.tensor([[100.0], [200.0]])  # shape (2,1)\n",
        "E = A + d\n",
        "print(\"A + d:\\n\", E)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CUDA vs CPU"
      ],
      "metadata": {
        "id": "_xICGLcXgzJV"
      },
      "id": "_xICGLcXgzJV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc026d1d-cbe1-4725-bbf9-bc5a8751aee9",
      "metadata": {
        "id": "dc026d1d-cbe1-4725-bbf9-bc5a8751aee9"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "x = torch.rand(20000, 20000)\n",
        "print(\"x device:\", x.device)\n",
        "y = (x @ x).mean()\n",
        "print(\"y cpu:\", y.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6db2d46-2510-44c8-aace-fc19d16f0874",
      "metadata": {
        "id": "c6db2d46-2510-44c8-aace-fc19d16f0874"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "x_dev = x.to(device)\n",
        "\n",
        "print(\"x_dev device:\", x_dev.device)\n",
        "\n",
        "# A quick operation on the chosen device\n",
        "y = (x_dev @ x_dev).mean()\n",
        "print(\"y:\", y.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computational Graph and Autograd"
      ],
      "metadata": {
        "id": "m9wECRJag4Ur"
      },
      "id": "m9wECRJag4Ur"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83b582f6-cacc-413b-b50c-e03e79ebe66f",
      "metadata": {
        "id": "83b582f6-cacc-413b-b50c-e03e79ebe66f"
      },
      "outputs": [],
      "source": [
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "w = torch.tensor(3.0, requires_grad=True)\n",
        "\n",
        "y = w * x + 1\n",
        "loss = (y - 10) ** 2\n",
        "\n",
        "print(\"y:\", y.item())\n",
        "print(\"loss:\", loss.item())\n",
        "print(\"loss.grad_fn:\", loss.grad_fn)  # this is part of a graph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c30af5e7-6b37-4a61-96ee-5c6a20ec7590",
      "metadata": {
        "id": "c30af5e7-6b37-4a61-96ee-5c6a20ec7590"
      },
      "outputs": [],
      "source": [
        "x = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "# Dynamic control flow: graph depends on runtime values\n",
        "y = x\n",
        "for i in range(5):\n",
        "    if y < 2.0:\n",
        "        y = y * 1.5\n",
        "    else:\n",
        "        y = y * 0.5\n",
        "    print(y)\n",
        "\n",
        "loss = (y - 1.0) ** 2\n",
        "loss.backward()\n",
        "\n",
        "print(\"final y:\", y.item())\n",
        "print(\"grad dx:\", x.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35530189-c8e8-43eb-82f9-488e79d7d827",
      "metadata": {
        "id": "35530189-c8e8-43eb-82f9-488e79d7d827"
      },
      "outputs": [],
      "source": [
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "y = x**3 + 2*x\n",
        "\n",
        "# dy/dx = 3x^2 + 2 => at x=2: 3*4+2=14\n",
        "y.backward()\n",
        "\n",
        "print(\"y:\", y.item())\n",
        "print(\"x.grad (expected 14):\", x.grad.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f84f8a3-65ee-471a-b64e-88e92b3ab376",
      "metadata": {
        "id": "9f84f8a3-65ee-471a-b64e-88e92b3ab376"
      },
      "outputs": [],
      "source": [
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "\n",
        "# First backward\n",
        "y1 = x**2\n",
        "y1.backward()\n",
        "print(\"After y1.backward(), x.grad:\", x.grad.item())  # 4\n",
        "\n",
        "# Second backward accumulates\n",
        "y2 = 3*x\n",
        "y2.backward()\n",
        "print(\"After y2.backward(), x.grad:\", x.grad.item())  # 4 + 3 = 7\n",
        "\n",
        "# Manually clear\n",
        "x.grad.zero_()\n",
        "print(\"After zero_(), x.grad:\", x.grad.item())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Backpropagation"
      ],
      "metadata": {
        "id": "SV9SrkBbhHK3"
      },
      "id": "SV9SrkBbhHK3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bcaa946-5623-43e4-9807-f6dbfd62b15a",
      "metadata": {
        "id": "4bcaa946-5623-43e4-9807-f6dbfd62b15a"
      },
      "outputs": [],
      "source": [
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "w = torch.tensor(3.0, requires_grad=True)\n",
        "\n",
        "y = w * x\n",
        "loss = (y - 1) ** 2\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print(\"loss:\", loss.item())\n",
        "print(\"dl/dx:\", x.grad.item())\n",
        "print(\"dl/dw:\", w.grad.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efe51c20-99c2-465e-9e13-930cd6fbee8d",
      "metadata": {
        "id": "efe51c20-99c2-465e-9e13-930cd6fbee8d"
      },
      "outputs": [],
      "source": [
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "w = torch.tensor(3.0, requires_grad=True)\n",
        "\n",
        "y = w * x\n",
        "L = (y - 1) ** 2\n",
        "L.backward()\n",
        "\n",
        "print(\"dy/dx =\", w.item())\n",
        "print(\"dL/dy =\", 2 * (y.item() - 1))\n",
        "print(\"autograd dL/dx =\", x.grad.item())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Function"
      ],
      "metadata": {
        "id": "sqFr9U9zhQNd"
      },
      "id": "sqFr9U9zhQNd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82b0d3f4-c9be-4ff5-86dd-2c1b3babcf27",
      "metadata": {
        "id": "82b0d3f4-c9be-4ff5-86dd-2c1b3babcf27"
      },
      "outputs": [],
      "source": [
        "y_true = torch.tensor([1.0, 2.0, 3.0])\n",
        "y_pred = torch.tensor([0.5, 2.5, 2.0], requires_grad=True)\n",
        "\n",
        "loss = torch.mean((y_pred - y_true) ** 2)\n",
        "loss.backward()\n",
        "\n",
        "print(\"MSE loss:\", loss.item())\n",
        "print(\"gradients:\", y_pred.grad)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d8a2869-dd7d-408e-ab29-d403053e6837",
      "metadata": {
        "id": "4d8a2869-dd7d-408e-ab29-d403053e6837"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "logits = torch.tensor([[2.0, 0.5, -1.0]], requires_grad=True)\n",
        "target = torch.tensor([0])  # class index\n",
        "\n",
        "loss = F.cross_entropy(logits, target)\n",
        "loss.backward()\n",
        "\n",
        "print(\"Cross-entropy loss:\", loss.item())\n",
        "print(\"Gradient w.r.t logits:\", logits.grad)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Update Rules and Optimizers"
      ],
      "metadata": {
        "id": "4RJzE42chX7M"
      },
      "id": "4RJzE42chX7M"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05b116ce-3312-4fed-8bb1-e07310751010",
      "metadata": {
        "id": "05b116ce-3312-4fed-8bb1-e07310751010"
      },
      "outputs": [],
      "source": [
        "x = torch.tensor(5.0, requires_grad=True)\n",
        "lr = 0.1\n",
        "\n",
        "for step in range(5):\n",
        "    loss = (x - 1) ** 2\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        x -= lr * x.grad\n",
        "        x.grad.zero_()\n",
        "\n",
        "    print(f\"step {step}: x={x.item():.4f}, loss={loss.item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53706fbc-6501-4e9e-bd71-041a6e7b5367",
      "metadata": {
        "id": "53706fbc-6501-4e9e-bd71-041a6e7b5367"
      },
      "outputs": [],
      "source": [
        "x = torch.tensor(5.0, requires_grad=True)\n",
        "optimizer = torch.optim.SGD([x], lr=0.1)\n",
        "\n",
        "for step in range(5):\n",
        "    loss = (x - 1) ** 2\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    print(f\"step {step}: x={x.item():.4f}, loss={loss.item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f407bfe4-19af-4cf1-b372-17978c2480c9",
      "metadata": {
        "id": "f407bfe4-19af-4cf1-b372-17978c2480c9"
      },
      "outputs": [],
      "source": [
        "w = torch.randn(1, requires_grad=True)\n",
        "optimizer = torch.optim.Adam([w], lr=0.1)\n",
        "\n",
        "for step in range(10):\n",
        "    x = torch.tensor(2.0)\n",
        "    y_true = torch.tensor(4.0)\n",
        "\n",
        "    y_pred = w * x # 1. Forward pass\n",
        "    loss = (y_pred - y_true) ** 2 # 2. Compute loss\n",
        "\n",
        "    loss.backward() # 3. Backward pass\n",
        "    optimizer.step() # 4. Update parameters\n",
        "    optimizer.zero_grad() # 5. Zero gradients\n",
        "\n",
        "    print(f\"step {step}: w={w.item():.3f}, loss={loss.item():.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multilayer Perceptrons"
      ],
      "metadata": {
        "id": "4JsAB2dYhjZk"
      },
      "id": "4JsAB2dYhjZk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3a1583b-54c7-4bdd-925f-88cf8d55d62f",
      "metadata": {
        "id": "e3a1583b-54c7-4bdd-925f-88cf8d55d62f"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# A simple 1-layer model\n",
        "model = nn.Linear(2, 1)\n",
        "\n",
        "print(model)\n",
        "print(\"Parameters:\")\n",
        "for name, p in model.named_parameters():\n",
        "    print(name, p.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "616b8982-70d7-43c0-b13c-07ab5dd13f90",
      "metadata": {
        "id": "616b8982-70d7-43c0-b13c-07ab5dd13f90"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "mlp = nn.Sequential(\n",
        "    nn.Linear(4, 16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16, 2)\n",
        ")\n",
        "\n",
        "print(mlp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9611f115-e451-429e-84da-001e3b3b251d",
      "metadata": {
        "id": "9611f115-e451-429e-84da-001e3b3b251d"
      },
      "outputs": [],
      "source": [
        "x = torch.linspace(-2, 2, 5)\n",
        "\n",
        "linear = nn.Linear(1, 1, bias=False)\n",
        "linear.weight.data.fill_(1.0)\n",
        "\n",
        "y_linear = linear(x.unsqueeze(1))\n",
        "y_relu = torch.relu(y_linear)\n",
        "\n",
        "print(\"x:\", x)\n",
        "print(\"linear:\", y_linear.squeeze())\n",
        "print(\"relu:\", y_relu.squeeze())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ceaaa278-9eb1-4e09-a93f-9c023ad827f4",
      "metadata": {
        "id": "ceaaa278-9eb1-4e09-a93f-9c023ad827f4"
      },
      "outputs": [],
      "source": [
        "x = torch.linspace(-3, 3, 7)\n",
        "y = torch.relu(x)\n",
        "\n",
        "print(\"x:\", x)\n",
        "print(\"ReLU(x):\", y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee2a72a8-a79b-43b2-bf74-aaab925b83a3",
      "metadata": {
        "id": "ee2a72a8-a79b-43b2-bf74-aaab925b83a3"
      },
      "outputs": [],
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(10, 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32, 3)  # 3 classes\n",
        ")\n",
        "\n",
        "x = torch.randn(5, 10)  # batch of 5 samples\n",
        "logits = model(x)\n",
        "\n",
        "print(\"logits shape:\", logits.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN and Demo"
      ],
      "metadata": {
        "id": "Hu_Bxp21hpIR"
      },
      "id": "Hu_Bxp21hpIR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5c19f83-e1cb-4a6e-9974-f2a1c0a80c6f",
      "metadata": {
        "id": "e5c19f83-e1cb-4a6e-9974-f2a1c0a80c6f"
      },
      "outputs": [],
      "source": [
        "conv = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3)\n",
        "\n",
        "print(conv)\n",
        "print(\"Number of parameters:\", sum(p.numel() for p in conv.parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0696afdd-d6a0-4d29-b947-27269071e03a",
      "metadata": {
        "id": "0696afdd-d6a0-4d29-b947-27269071e03a"
      },
      "outputs": [],
      "source": [
        "cnn_block = nn.Sequential(\n",
        "    nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2)\n",
        ")\n",
        "\n",
        "print(cnn_block)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3079c0cf-6376-4529-a641-5b344225c6f2",
      "metadata": {
        "id": "3079c0cf-6376-4529-a641-5b344225c6f2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def vgg_block(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0e32c25-619e-424d-aec3-b5dfddeb0a33",
      "metadata": {
        "id": "a0e32c25-619e-424d-aec3-b5dfddeb0a33"
      },
      "outputs": [],
      "source": [
        "class VGGNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            vgg_block(3, 64),     # 32×32 → 16×16\n",
        "            vgg_block(64, 128),   # 16×16 → 8×8\n",
        "            vgg_block(128, 256),  # 8×8 → 4×4\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256 * 4 * 4, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)  # flatten\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd5cbb2d-8b66-4b96-a01e-4ff9eab29f2c",
      "metadata": {
        "id": "fd5cbb2d-8b66-4b96-a01e-4ff9eab29f2c"
      },
      "outputs": [],
      "source": [
        "model = VGGNet(num_classes=10)\n",
        "print(model)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total parameters: {total_params:,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6364afbd-c02d-40bf-90f8-b2711ae1c18e",
      "metadata": {
        "id": "6364afbd-c02d-40bf-90f8-b2711ae1c18e"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=True, download=True, transform=transform\n",
        ")\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=64, shuffle=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dab6fb30-1b3f-4d6d-865b-fd93a9a1bee6",
      "metadata": {
        "id": "dab6fb30-1b3f-4d6d-865b-fd93a9a1bee6"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in trainloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader):.4f}\")\n"
      ],
      "metadata": {
        "id": "qLiLOWz794ED"
      },
      "id": "qLiLOWz794ED",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in trainloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Training accuracy: {100 * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "id": "Ica4TK8m97kZ"
      },
      "id": "Ica4TK8m97kZ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}